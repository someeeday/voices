"""
üöÄ –ü—Ä–æ—Å—Ç–æ–π Intel Ultra 9 –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω–æ–≥–æ CPU –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""

import os
import sys
import logging
import psutil
from typing import Dict, Any, Optional, Tuple
import torch
import numpy as np
from pathlib import Path
import time

# –ü—Ä–æ—Å—Ç—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
try:
    import mkl
    MKL_AVAILABLE = True
except ImportError:
    MKL_AVAILABLE = False


class SimpleIntelOptimizer:
    """
    –ü—Ä–æ—Å—Ç–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è Intel Ultra 9 –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –ú–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã–π CPU —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
    - Intel MKL –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    - PyTorch –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏
    """
    
    def __init__(self, logger: Optional[logging.Logger] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            logger: –õ–æ–≥–≥–µ—Ä –¥–ª—è –≤—ã–≤–æ–¥–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        """
        self.logger = logger or logging.getLogger(__name__)
        
        # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        self.cpu_count = psutil.cpu_count(logical=True)
        self.cpu_count_physical = psutil.cpu_count(logical=False)
        self.memory_gb = psutil.virtual_memory().total / (1024**3)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.config = {
            "use_optimized_cpu": True,
            "num_threads": None,
            "mixed_precision": False,  # –û—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            "jit_compile": True
        }
        
        self._optimize_environment()
    
    def _optimize_environment(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Intel Ultra 9"""
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ—Ç–æ–∫–æ–≤
        optimal_threads = min(self.cpu_count_physical, 16)  # –ù–µ –±–æ–ª–µ–µ 16 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        
        # PyTorch –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        torch.set_num_threads(optimal_threads)
        self.config["num_threads"] = optimal_threads
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        os.environ["OMP_NUM_THREADS"] = str(optimal_threads)
        os.environ["NUMEXPR_NUM_THREADS"] = str(optimal_threads)
        
        # Intel MKL –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        if MKL_AVAILABLE:
            try:
                mkl.set_num_threads(optimal_threads)
                os.environ["MKL_NUM_THREADS"] = str(optimal_threads)
                self.logger.info(f"üîß Intel MKL –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {optimal_threads} –ø–æ—Ç–æ–∫–æ–≤")
            except Exception as e:
                self.logger.debug(f"–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ MKL: {e}")
        
        # –í–∫–ª—é—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π –¥–ª—è Intel CPU
        if hasattr(torch.backends, 'mkldnn'):
            torch.backends.mkldnn.enabled = True
        
        # OpenMP –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        os.environ["KMP_BLOCKTIME"] = "1"
        os.environ["KMP_AFFINITY"] = "granularity=fine,compact,1,0"
        
        self.logger.info(f"‚öôÔ∏è –û–∫—Ä—É–∂–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è Intel Ultra 9: {optimal_threads} –ø–æ—Ç–æ–∫–æ–≤")
    
    def get_optimal_torch_device(self) -> torch.device:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ PyTorch —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        
        Returns:
            CPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
        """
        return torch.device("cpu")
    
    def optimize_model(self, model: torch.nn.Module, 
                      sample_input: Optional[torch.Tensor] = None) -> torch.nn.Module:
        """
        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è PyTorch –º–æ–¥–µ–ª–∏ –¥–ª—è Intel Ultra 9
        
        Args:
            model: PyTorch –º–æ–¥–µ–ª—å
            sample_input: –ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            
        Returns:
            –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        """
        device = self.get_optimal_torch_device()
        
        # –ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –Ω–∞ CPU
        model = model.to(device)
        
        # JIT –∫–æ–º–ø–∏–ª—è—Ü–∏—è –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
        if self.config["jit_compile"] and sample_input is not None:
            try:
                sample_input = sample_input.to(device)
                model.eval()
                with torch.no_grad():
                    # –°–æ–∑–¥–∞–µ–º traced –º–æ–¥–µ–ª—å
                    traced_model = torch.jit.trace(model, sample_input)
                    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –¥–ª—è inference
                    traced_model = torch.jit.optimize_for_inference(traced_model)
                    self.logger.info("‚ö° JIT –∫–æ–º–ø–∏–ª—è—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω—ã")
                    return traced_model
            except Exception as e:
                self.logger.debug(f"JIT –∫–æ–º–ø–∏–ª—è—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
        
        return model
    
    def optimize_dataloader(self, dataloader_kwargs: Dict) -> Dict:
        """
        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è DataLoader –¥–ª—è –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        
        Args:
            dataloader_kwargs: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã DataLoader
            
        Returns:
            –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        """
        # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ worker'–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        optimal_workers = min(self.cpu_count_physical, 8)  # –ù–µ –±–æ–ª–µ–µ 8 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        
        dataloader_kwargs.update({
            "num_workers": optimal_workers,
            "pin_memory": False,  # –î–ª—è CPU –Ω–µ –Ω—É–∂–Ω–æ
            "persistent_workers": True if optimal_workers > 0 else False,
            "prefetch_factor": 2 if optimal_workers > 0 else None
        })
        
        self.logger.info(f"üìä DataLoader –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω: {optimal_workers} worker'–æ–≤")
        return dataloader_kwargs
    
    def get_training_config(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
        
        Returns:
            –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        """
        # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        config = {
            "device": str(self.get_optimal_torch_device()),
            "mixed_precision": self.config["mixed_precision"],
            "compile_model": self.config["jit_compile"],
            "pin_memory": False,
            "non_blocking": False
        }
        
        # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏ –∏ —è–¥–µ—Ä
        if self.memory_gb >= 32:
            config["batch_size"] = 128
        elif self.memory_gb >= 16:
            config["batch_size"] = 64
        else:
            config["batch_size"] = 32
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø–æ–¥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–¥–µ—Ä
        if self.cpu_count_physical >= 8:
            config["batch_size"] = min(config["batch_size"], 96)
        elif self.cpu_count_physical >= 4:
            config["batch_size"] = min(config["batch_size"], 64)
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ worker'–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        config["num_workers"] = min(self.cpu_count_physical, 8)
        
        return config
    
    def benchmark_cpu_performance(self, model: torch.nn.Module, 
                                 sample_input: torch.Tensor, 
                                 num_iterations: int = 100) -> Dict[str, float]:
        """
        –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ CPU
        
        Args:
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            sample_input: –ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            num_iterations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è —Ç–µ—Å—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ (–≤—Ä–µ–º—è –≤ –º—Å)
        """
        results = {}
        
        try:
            device = torch.device("cpu")
            test_model = model.to(device)
            test_input = sample_input.to(device)
            
            # –¢–µ—Å—Ç –æ–±—ã—á–Ω–æ–π –º–æ–¥–µ–ª–∏
            test_model.eval()
            # –ü—Ä–æ–≥—Ä–µ–≤
            with torch.no_grad():
                for _ in range(10):
                    _ = test_model(test_input)
            
            # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
            start_time = time.time()
            with torch.no_grad():
                for _ in range(num_iterations):
                    _ = test_model(test_input)
            end_time = time.time()
            
            avg_time_ms = (end_time - start_time) * 1000 / num_iterations
            results["cpu_normal"] = avg_time_ms
            
            # –¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            try:
                optimized_model = self.optimize_model(test_model, test_input)
                
                # –ü—Ä–æ–≥—Ä–µ–≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                with torch.no_grad():
                    for _ in range(10):
                        _ = optimized_model(test_input)
                
                # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                start_time = time.time()
                with torch.no_grad():
                    for _ in range(num_iterations):
                        _ = optimized_model(test_input)
                end_time = time.time()
                
                avg_time_optimized_ms = (end_time - start_time) * 1000 / num_iterations
                results["cpu_optimized"] = avg_time_optimized_ms
                
                # –í—ã—á–∏—Å–ª—è–µ–º —É—Å–∫–æ—Ä–µ–Ω–∏–µ
                speedup = avg_time_ms / avg_time_optimized_ms
                results["speedup"] = speedup
                
            except Exception as e:
                self.logger.debug(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
            
            self.logger.info(f"‚è±Ô∏è CPU –æ–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å: {results.get('cpu_normal', 0):.2f} –º—Å/–∏—Ç–µ—Ä–∞—Ü–∏—è")
            if "cpu_optimized" in results:
                self.logger.info(f"‚ö° CPU –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è: {results['cpu_optimized']:.2f} –º—Å/–∏—Ç–µ—Ä–∞—Ü–∏—è")
                self.logger.info(f"üöÄ –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {results.get('speedup', 1):.2f}x")
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}")
        
        return results
    
    def get_system_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ
        
        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ö
        """
        return {
            "cpu": {
                "physical_cores": self.cpu_count_physical,
                "logical_cores": self.cpu_count,
                "optimal_threads": self.config.get("num_threads", self.cpu_count)
            },
            "memory": {
                "total_gb": round(self.memory_gb, 1),
                "available_gb": round(psutil.virtual_memory().available / (1024**3), 1)
            },
            "optimizations": {
                "mkl_available": MKL_AVAILABLE,
                "torch_threads": torch.get_num_threads(),
                "mkldnn_enabled": getattr(torch.backends.mkldnn, 'enabled', False)
            },
            "optimal_device": "Optimized CPU",
            "config": self.config
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
_simple_intel_optimizer = None

def get_simple_intel_optimizer(logger: Optional[logging.Logger] = None) -> SimpleIntelOptimizer:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ Intel –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞"""
    global _simple_intel_optimizer
    if _simple_intel_optimizer is None:
        _simple_intel_optimizer = SimpleIntelOptimizer(logger)
    return _simple_intel_optimizer
